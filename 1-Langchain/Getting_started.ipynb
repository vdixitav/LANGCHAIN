{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "#langsmith tracking\n",
    "os.environ['LANGCHAIN_API_KEY']=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x0000020D36888EB0> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000020D36A88970> root_client=<openai.OpenAI object at 0x0000020D3688AC80> root_async_client=<openai.AsyncOpenAI object at 0x0000020D36888F10> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inpute and get response from llm\n",
    "\n",
    "result=llm.invoke(\"what is generative AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a class of artificial intelligence models designed to generate new content. These models learn patterns from existing data and use that understanding to create novel outputs that mimic the original data's style or structure. Generative AI can produce a wide range of content types, including text, images, music, and even video. Some of the most notable examples of generative AI include:\\n\\n1. **Text Generation**: Models like OpenAI's GPT (Generative Pre-trained Transformer) can write essays, articles, and even poetry by predicting and generating text based on the input prompt.\\n\\n2. **Image Generation**: Tools such as DALL-E and Stable Diffusion can create original images from textual descriptions, allowing for the generation of art, design concepts, and more.\\n\\n3. **Music and Audio Generation**: AI models can compose music by learning from existing compositions, generating new pieces in similar styles or genres.\\n\\n4. **Video Generation**: Though more complex, some AI systems can generate short video clips based on learned patterns in visual and audio data.\\n\\nGenerative AI has a wide range of applications, including creative industries, entertainment, design, and even scientific research. However, it also raises ethical concerns, such as the potential for misuse in creating deepfakes or generating misleading information. Nonetheless, generative AI continues to evolve, offering innovative tools and possibilities across various fields.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 278, 'prompt_tokens': 12, 'total_tokens': 290, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cc5cf1c6e3', 'finish_reason': 'stop', 'logprobs': None} id='run-91daa9fa-72c1-4ac3-9393-6e27bf68ce74-0' usage_metadata={'input_tokens': 12, 'output_tokens': 278, 'total_tokens': 290, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. provide me answeer based on questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatpromet templet\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "promt= ChatPromptTemplate.from_messages( \n",
    "\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. provide me answeer based on questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain is combining \n",
    "chain=promt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"can you tell me about langsmith?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"LangSmith is a toolset developed by LangChain to enhance the development, testing, and management of applications that rely on large language models (LLMs). It offers a range of features to streamline the process of building applications with LLMs, focusing on key areas such as observability, testing, evaluation, and debugging. LangSmith's capabilities allow developers to track and understand the behavior of their LLM applications more effectively, ensuring they are functioning as intended and meeting desired performance standards. By providing these tools, LangSmith helps developers to optimize their use of language models, resulting in more efficient and reliable applications.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 122, 'prompt_tokens': 33, 'total_tokens': 155, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cc5cf1c6e3', 'finish_reason': 'stop', 'logprobs': None} id='run-f2af7e3b-9d73-4110-be21-dbcc56ce76f6-0' usage_metadata={'input_tokens': 33, 'output_tokens': 122, 'total_tokens': 155, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a tool designed to enhance the development and debugging of applications that utilize large language models (LLMs). It provides a platform for testing, evaluating, and monitoring LLM-based applications by offering features such as prompt management, dataset creation, and comprehensive evaluation metrics. LangSmith is particularly useful for developers looking to iterate quickly and improve the performance and reliability of their language model applications. It integrates with various LLMs and helps manage the complexities involved in working with advanced language technologies.\n"
     ]
    }
   ],
   "source": [
    "### string output parser\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "output_parser=StrOutputParser()\n",
    "chain=promt|llm|output_parser\n",
    "\n",
    "\n",
    "response=chain.invoke({\"input\":\"can you tell me about langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
